<!DOCTYPE html>






  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />










  <meta name="baidu-site-verification" content="FKCjZBAwDZ" />













<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.2.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.2.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.2.0',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  

<script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>
<script>
  if (window.netlifyIdentity) {
    window.netlifyIdentity.on("init", user => {
      if (!user) {
        window.netlifyIdentity.on("login", () => {
          document.location.href = "/admin/";
        });
      }
    });
  }
</script>


  <meta name="description" content="My notes of UC Berkeley online course Intro to Artificial Intelligence">
<meta name="keywords" content="cs188,Artificial Intelligence,UC Berkeley">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes of cs188 Artificial Intelligence">
<meta property="og:url" content="http://henryhoo.github.io/cs188/index.html">
<meta property="og:site_name" content="Jiaxi He">
<meta property="og:description" content="My notes of UC Berkeley online course Intro to Artificial Intelligence">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNc79gy1fsq1quaa3vj31a20e2wg6.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tKfTcly1fsr653uff3j30hu0emaa5.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1fsvld0v2gwj312y0lkwfi.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tNc79ly1fsvlmsbeimj30q802idft.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1fsvlo457t4j31c80oiwfg.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1fsvljq45ooj30rm034dfu.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tKfTcgy1fszvbs9pfuj31ik0s8gn4.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tKfTcgy1ft0098h4lej31jw0soq3y.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tKfTcgy1ft00ce42xej31j20swjs9.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tKfTcgy1ft00hjx84oj31ja0nidhz.jpg">
<meta property="og:updated_time" content="2018-07-06T13:08:01.948Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Notes of cs188 Artificial Intelligence">
<meta name="twitter:description" content="My notes of UC Berkeley online course Intro to Artificial Intelligence">
<meta name="twitter:image" content="https://ws1.sinaimg.cn/large/006tNc79gy1fsq1quaa3vj31a20e2wg6.jpg">






  <link rel="canonical" href="http://henryhoo.github.io/cs188/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Notes of cs188 Artificial Intelligence | Jiaxi He</title>
  






  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5cb1205e2ee7921b3a3636edfe6a588a";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jiaxi He</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>




<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />About</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />Tags</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />Categories</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-top">
    <a href="/top/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-signal"></i> <br />top</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />Search</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://henryhoo.github.io/cs188/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaxi He">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaxi He">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Notes of cs188 Artificial Intelligence
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-06-27 08:47:04" itemprop="dateCreated datePublished" datetime="2018-06-27T08:47:04-07:00">2018-06-27</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-07-06 06:08:01" itemprop="dateModified" datetime="2018-07-06T06:08:01-07:00">2018-07-06</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">Notes</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Notes/Computer-Science/" itemprop="url" rel="index"><span itemprop="name">Computer Science</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/cs188/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">Comments: </span> <span class="post-comments-count gitment-comments-count" data-xid="/cs188/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/cs188/" class="leancloud_visitors" data-flag-title="Notes of cs188 Artificial Intelligence">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>My notes of UC Berkeley online course <a href="https://www.bilibili.com/video/av15628609/?p=5" target="_blank" rel="noopener">Intro to Artificial Intelligence</a><br><a id="more"></a></p>
<h2 id="Search"><a href="#Search" class="headerlink" title="Search"></a>Search</h2><h3 id="Two-type-of-search"><a href="#Two-type-of-search" class="headerlink" title="Two type of search"></a>Two type of search</h3><h4 id="Planning-sequences-of-actions"><a href="#Planning-sequences-of-actions" class="headerlink" title="Planning: sequences of actions"></a>Planning: sequences of actions</h4><ul>
<li>The path to the goal is the important thing</li>
<li>Paths have various costs, depths</li>
<li>Heuristics give problem-specific guidance</li>
</ul>
<h4 id="Identification-assignments-to-variables"><a href="#Identification-assignments-to-variables" class="headerlink" title="Identification: assignments to variables"></a>Identification: assignments to variables</h4><ul>
<li>The goal itself is important, not the path</li>
<li>All paths at the same depth (for some formulations)</li>
<li>CSPs are specialized for identification problems</li>
</ul>
<h3 id="Uninformed-and-Informed-Search-Planning"><a href="#Uninformed-and-Informed-Search-Planning" class="headerlink" title="Uninformed and Informed Search (Planning)"></a>Uninformed and Informed Search (Planning)</h3><ul>
<li>All search algorithms are the same except for fringe strategies.</li>
<li><strong>Informed Search</strong>: Introduced heuristic to estimate of distance to nearest goal for each state and therefore speed up search (Solve performance problem of UCS).</li>
</ul>
<h4 id="Abstraction"><a href="#Abstraction" class="headerlink" title="Abstraction"></a>Abstraction</h4><ul>
<li>A state space.</li>
<li>A successor function (with actions, costs).</li>
<li>A start state and a goal test.</li>
</ul>
<h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><ul>
<li>Traveling in Romania (Map with weighted edge)</li>
<li>Pac-man game planning</li>
<li>Pancake Problem</li>
</ul>
<h4 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h4><ul>
<li>Complete: Guaranteed to find a solution if one exists?</li>
<li>Optimal: Guaranteed to find the least cost path?</li>
<li>Time and space complexity.</li>
</ul>
<h4 id="Depth-First-Search-DFS"><a href="#Depth-First-Search-DFS" class="headerlink" title="Depth-First Search (DFS)"></a>Depth-First Search (DFS)</h4><ul>
<li>Complete if we prevent cycles</li>
<li>Not optimal</li>
<li>Time O(b^m)</li>
<li>Space O(bm)</li>
</ul>
<h4 id="Breadth-First-Search-BFS"><a href="#Breadth-First-Search-BFS" class="headerlink" title="Breadth-First Search (BFS)"></a>Breadth-First Search (BFS)</h4><ul>
<li>Complete</li>
<li>Optimal only if costs are all 1</li>
<li>Time O(b^s)</li>
<li>Space O(b^s)</li>
</ul>
<h4 id="Uniform-Cost-Search-UCS"><a href="#Uniform-Cost-Search-UCS" class="headerlink" title="Uniform Cost Search (UCS)"></a>Uniform Cost Search (UCS)</h4><ul>
<li>Complete and optimal</li>
<li>Time O(b^(C*/E))  </li>
<li>Space O(b^(C*/E))</li>
<li><strong>Problem</strong>: Explores options in every “direction” because no information about goal location</li>
</ul>
<h4 id="Greedy-Search"><a href="#Greedy-Search" class="headerlink" title="Greedy Search"></a>Greedy Search</h4><ul>
<li>Expand the node that seems closest</li>
<li><strong>Can be wrong</strong> because of this (not optimal)</li>
</ul>
<h4 id="A-Combining-UCS-and-Greedy"><a href="#A-Combining-UCS-and-Greedy" class="headerlink" title="A*: Combining UCS and Greedy"></a>A*: Combining UCS and Greedy</h4><p>Uniform-cost orders by path cost, or backward cost <strong>g(n)</strong>. Greedy orders by goal proximity, or forward cost <strong>h(n)</strong>. A* Search orders by the sum: <strong>f(n) = g(n) + h(n)</strong>.</p>
<h5 id="Admissibility"><a href="#Admissibility" class="headerlink" title="Admissibility"></a>Admissibility</h5><ul>
<li>Inadmissible (pessimistic) heuristics break optimality by trapping good plans on the fringe</li>
<li>Admissible (optimistic) heuristics slow down bad plans but never outweigh true costs</li>
<li>A heuristic h is admissible (optimistic) if: 0 &lt;= h(n) &lt;= h<em>(n) where h</em>(n) is the true cost to a nearest goal.</li>
</ul>
<h5 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h5><p>Heuristic “arc” cost ≤ actual cost for each arc: h(A) – h(C) ≤ cost(A to C)</p>
<h5 id="Heuristic-design"><a href="#Heuristic-design" class="headerlink" title="Heuristic design"></a>Heuristic design</h5><p>A* is <strong>optimal</strong> with admissible/consistent heuristics. In general, most natural admissible heuristics tend to be consistent, especially if from relaxed problems so often use relaxed problems.</p>
<h5 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h5><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fsq1quaa3vj31a20e2wg6.jpg" alt=""></p>
<h3 id="Constraint-Satisfaction-Problems-Identification"><a href="#Constraint-Satisfaction-Problems-Identification" class="headerlink" title="Constraint Satisfaction Problems (Identification)"></a>Constraint Satisfaction Problems (Identification)</h3><h4 id="Abstraction-1"><a href="#Abstraction-1" class="headerlink" title="Abstraction"></a>Abstraction</h4><ul>
<li>A special subset of search problems</li>
<li>State is defined by variables Xi  with values from a domain D (sometimes D depends on i)</li>
<li>Goal test is a set of constraints specifying allowable combinations of values for subsets of variables</li>
</ul>
<h4 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h4><ul>
<li>Map Coloring</li>
<li>N-Queens</li>
<li>Cryptarithmetic</li>
<li>Sudoku</li>
</ul>
<h4 id="Backtracking-Search"><a href="#Backtracking-Search" class="headerlink" title="Backtracking Search"></a>Backtracking Search</h4><p>Backtracking search is the basic uninformed algorithm for solving CSPs</p>
<ul>
<li><p><strong>idea 1: One variable at a time</strong>: Variable assignments are commutative, so only need to consider assignments to a single variable at each step</p>
</li>
<li><p><strong>Idea 2: Check constraints as you go</strong>: Consider only values which do not conflict previous assignments. (Might have to do some computation to check the constraints “Incremental goal test”)</p>
</li>
</ul>
<h4 id="Improving-Backtracking"><a href="#Improving-Backtracking" class="headerlink" title="Improving Backtracking"></a>Improving Backtracking</h4><h5 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h5><p>Detect inevitable failure early: Keep track of domains for unassigned variables and cross off bad options.</p>
<h6 id="Forward-Checking"><a href="#Forward-Checking" class="headerlink" title="Forward Checking"></a>Forward Checking</h6><p>Cross off values that violate a constraint when added to the existing assignment.</p>
<p><strong>Disadvantage</strong>: doesn’t provide early detection for all failures.</p>
<h6 id="Constraint-Propagation"><a href="#Constraint-Propagation" class="headerlink" title="Constraint Propagation"></a>Constraint Propagation</h6><p>Forward checking propagates information from assigned to unassigned variables, but doesn’t provide early detection for all failures.</p>
<p>So introduce <strong>Arc consistent</strong>: An arc X-&gt;Y is consistent iff for every x in the tail there is some y in the head which could be assigned without violating a constraint.</p>
<p>A simple form of propagation makes sure all arcs are consistent.</p>
<p><strong>Disadvantage</strong>: Running slow and can not detect all failures.</p>
<h6 id="K-Consistency"><a href="#K-Consistency" class="headerlink" title="K-Consistency"></a>K-Consistency</h6><ul>
<li><p>1-Consistency (Node Consistency): Each single node’s domain has a value which meets that node’s unary constraints</p>
</li>
<li><p>2-Consistency (Arc Consistency): For each pair of nodes, any consistent assignment to one can be extended to the other</p>
</li>
<li><p>K-Consistency: For each k nodes, any consistent assignment to k-1 can be extended to the kth node.</p>
</li>
</ul>
<h6 id="Strong-K-Consistency"><a href="#Strong-K-Consistency" class="headerlink" title="Strong K-Consistency"></a>Strong K-Consistency</h6><p>k, k-1…1 Consistency which means we can solve without backtracking.</p>
<h5 id="Ordering"><a href="#Ordering" class="headerlink" title="Ordering"></a>Ordering</h5><h6 id="Minimum-remaining-values-MRV"><a href="#Minimum-remaining-values-MRV" class="headerlink" title="Minimum remaining values (MRV)"></a>Minimum remaining values (MRV)</h6><p>Choose the variable with the fewest legal left values in its domain (“Fail-fast” ordering)</p>
<h6 id="Least-Constraining-Value-LCV"><a href="#Least-Constraining-Value-LCV" class="headerlink" title="Least Constraining Value (LCV)"></a>Least Constraining Value (LCV)</h6><p>Given a choice of variable, choose the least constraining value which leave more choices for future. I.e., the one that rules out the fewest values in the remaining variables. Note that it may take some computation to determine this!  (E.g., rerunning filtering)</p>
<h5 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h5><h6 id="Subproblems"><a href="#Subproblems" class="headerlink" title="Subproblems"></a>Subproblems</h6><p>Independent subproblems are identifiable as connected components of constraint graph. Solve subproblems Independently will speed things up based on # of variables of subproblems.</p>
<h6 id="Tree-Structured-CSPs"><a href="#Tree-Structured-CSPs" class="headerlink" title="Tree-Structured CSPs"></a>Tree-Structured CSPs</h6><p>If the constraint graph has no loops, the CSP can be solved in <strong>O(n d^2)</strong> time compared to general CSPs, where worst-case time is <strong>O(d^n)</strong></p>
<h6 id="Cutset"><a href="#Cutset" class="headerlink" title="Cutset"></a>Cutset</h6><p>Instantiate (in all ways) a set of variables such that the remaining constraint graph is a <strong>tree structure CSP</strong>, which reduce runtime to <strong>O((d^c)<em>(n-c)</em>d^2)</strong>.</p>
<h4 id="Local-search-Iterative-Algorithms-for-CSPs"><a href="#Local-search-Iterative-Algorithms-for-CSPs" class="headerlink" title="Local search: Iterative Algorithms for CSPs"></a>Local search: Iterative Algorithms for CSPs</h4><p>Take an assignment with unsatisfied constraints, operators reassign variable values until problem solved.</p>
<h5 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h5><p>The same appears to be true for any randomly-generated CSP except in a narrow range of the ratio<br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fsr653uff3j30hu0emaa5.jpg" alt=""></p>
<h3 id="Adversarial-Search-Minimax-Tree"><a href="#Adversarial-Search-Minimax-Tree" class="headerlink" title="Adversarial Search (Minimax Tree)"></a>Adversarial Search (Minimax Tree)</h3><ul>
<li>Just like DFS: Time: O(b^m), Space: O(bm).</li>
<li>Optimal against a perfect player but do not reasoning against possible outcome.</li>
</ul>
<h4 id="Resource-Limits"><a href="#Resource-Limits" class="headerlink" title="Resource Limits"></a>Resource Limits</h4><p>Hard to search all leaves of tree (bound by time).</p>
<h5 id="Solution1-Depth-limited-search"><a href="#Solution1-Depth-limited-search" class="headerlink" title="Solution1: Depth limited search"></a>Solution1: Depth limited search</h5><p>Search only to a limited depth in the tree, replace terminal utilities with an evaluation function for non-terminal positions.</p>
<h6 id="Properties-1"><a href="#Properties-1" class="headerlink" title="Properties"></a>Properties</h6><ul>
<li>Guarantee of optimal play is gone</li>
<li>The deeper in the tree the evaluation function is buried, the less the quality of the evaluation function matters</li>
<li>Tradeoff between complexity of features and complexity of computation</li>
</ul>
<h6 id="Evaluation-Functions"><a href="#Evaluation-Functions" class="headerlink" title="Evaluation Functions"></a>Evaluation Functions</h6><ul>
<li>Typically weighted linear sum of features</li>
<li>Have danger of replanning</li>
</ul>
<h5 id="Solution2-Alpha-Beta-Pruning"><a href="#Solution2-Alpha-Beta-Pruning" class="headerlink" title="Solution2: Alpha-Beta Pruning"></a>Solution2: Alpha-Beta Pruning</h5><p>Reduce unnecessary compute if possible.</p>
<h6 id="General-steps"><a href="#General-steps" class="headerlink" title="General steps"></a>General steps</h6><p>(MIN version, MAX version is symmetric)</p>
<ol>
<li>We’re computing the MIN-VALUE at some node n</li>
<li>We’re looping over n’s children</li>
<li>n’s estimate of the children’s min is dropping</li>
<li>Who cares about n’s value?  MAX</li>
<li>Let a be the best value that MAX can get at any choice point along the current path from the root</li>
<li>If n becomes worse than a, MAX will avoid it, so we can stop considering n’s other children (it’s already bad enough that it won’t be played)</li>
</ol>
<h6 id="Properties-2"><a href="#Properties-2" class="headerlink" title="Properties"></a>Properties</h6><ul>
<li>No effect on minimax value computed for the root!</li>
<li>Values of intermediate nodes might be wrong</li>
<li>Good child ordering improves effectiveness of pruning</li>
<li>A simple example of meta-reasoning: computing about what to compute</li>
</ul>
<h3 id="Uncertainty-and-Utilities"><a href="#Uncertainty-and-Utilities" class="headerlink" title="Uncertainty and Utilities"></a>Uncertainty and Utilities</h3><p>Uncertain outcomes controlled by chance (EXP node), not an adversary (MIN node).</p>
<h4 id="Expectimax-Search"><a href="#Expectimax-Search" class="headerlink" title="Expectimax Search"></a>Expectimax Search</h4><p>Replace MIN node with EXP node</p>
<ul>
<li>MAX nodes as in minimax search.</li>
<li>Chance nodes are like MIN nodes but the outcome is uncertain.</li>
<li>Calculate their <strong>expected utilities</strong>. I.e. take weighted average (expectation) of children.</li>
<li>Hard to prune if using average.</li>
<li>For evaluation, magnitude become important other than ordering.</li>
</ul>
<h4 id="Expectiminmax-Search-Mixed-Layer"><a href="#Expectiminmax-Search-Mixed-Layer" class="headerlink" title="Expectiminmax Search (Mixed Layer)"></a>Expectiminmax Search (Mixed Layer)</h4><p>Ad EXP node between MAX and MIN node.</p>
<ul>
<li>Environment is an extra “random agent” player that moves after each min/max agent</li>
<li>Each node computes the appropriate combination of its children</li>
</ul>
<h5 id="Properties-3"><a href="#Properties-3" class="headerlink" title="Properties"></a>Properties</h5><p>As depth increases, probability of reaching a given search node shrinks</p>
<ul>
<li>So usefulness of search is diminished</li>
<li>So limiting depth is less damaging</li>
<li>But <strong>pruning</strong> is trickier</li>
</ul>
<h5 id="Example-2"><a href="#Example-2" class="headerlink" title="Example"></a>Example</h5><p>Historic AI: TDGammon uses depth-2 search + very good evaluation function + reinforcement learning: world-champion level play.</p>
<h4 id="Generalization-of-minimax"><a href="#Generalization-of-minimax" class="headerlink" title="Generalization of minimax"></a>Generalization of minimax</h4><ul>
<li>Terminals have utility tuples.</li>
<li>Node values are also utility tuples.</li>
<li>Each player maximizes its own component.</li>
<li>Can give rise to cooperation and competition dynamically and naturally.</li>
</ul>
<h4 id="Maximum-Expected-Utility-Principle"><a href="#Maximum-Expected-Utility-Principle" class="headerlink" title="Maximum Expected Utility Principle"></a>Maximum Expected Utility Principle</h4><ul>
<li>A rational agent should chose the action that <strong>maximizes its expected utility, given its knowledge.</strong></li>
<li>Note: an agent can be entirely rational (consistent with MEU) without ever representing or manipulating utilities and probabilities. E.g., a lookup table for perfect tic-tac-toe, a reflex vacuum cleaner</li>
</ul>
<h2 id="Markov-Decision-Processes-MDP"><a href="#Markov-Decision-Processes-MDP" class="headerlink" title="Markov Decision Processes (MDP)"></a>Markov Decision Processes (MDP)</h2><p>Agent do not have fully control over future (action). “Markov” generally means that given the present state, the future and the past are independent.</p>
<h3 id="Abstraction-2"><a href="#Abstraction-2" class="headerlink" title="Abstraction"></a>Abstraction</h3><ul>
<li>A set of states s</li>
<li>A set of actions a</li>
<li>A transition function T(s, a, s’)<ul>
<li>Probability that a from s leads to s’, i.e., P(s’| s, a)</li>
<li>Also called the model or the dynamics</li>
</ul>
</li>
<li>A reward function R(s, a, s’)<ul>
<li>Sometimes just R(s) or R(s’)</li>
</ul>
</li>
<li>A start state</li>
<li>Maybe a terminal state</li>
</ul>
<h3 id="Quantities"><a href="#Quantities" class="headerlink" title="Quantities"></a>Quantities</h3><ul>
<li>Policy = map of states to actions</li>
<li>Utility = sum of discounted rewards</li>
<li>Values = expected future utility from a state (max node)</li>
<li>Q-Values = expected future utility from a q-state (chance node)</li>
<li>The value (utility) of a state s: V*(s) = expected utility starting in s and acting optimally</li>
<li>The value (utility) of a q-state (s,a): Q*(s,a) = expected utility starting out having taken action a from state s and (thereafter) acting optimally</li>
<li>The optimal policy: t*(s) = optimal action from state s</li>
</ul>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><ul>
<li>Noisy movement</li>
<li>Racing car states</li>
</ul>
<h3 id="Utilities-of-Sequences"><a href="#Utilities-of-Sequences" class="headerlink" title="Utilities of Sequences"></a>Utilities of Sequences</h3><h4 id="Discounting"><a href="#Discounting" class="headerlink" title="Discounting"></a>Discounting</h4><ul>
<li>It’s reasonable to maximize the sum of rewards</li>
<li>It’s also reasonable to prefer rewards now to rewards later</li>
<li>So use discounting: values of rewards decay exponentially</li>
</ul>
<h5 id="Example-discount-of-0-5"><a href="#Example-discount-of-0-5" class="headerlink" title="Example: discount of 0.5"></a>Example: discount of 0.5</h5><ul>
<li>U([1,2,3]) = 1<em>1 + 0.5</em>2 + 0.25*3</li>
<li>U([1,2,3]) &lt; U([3,2,1])</li>
</ul>
<h4 id="Infinite-Utilities"><a href="#Infinite-Utilities" class="headerlink" title="Infinite Utilities"></a>Infinite Utilities</h4><p>What if the game lasts forever?  Do we get infinite rewards?</p>
<h5 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h5><ol>
<li><p>Finite horizon: (similar to depth-limited search)</p>
<ul>
<li>Terminate episodes after a fixed T steps (e.g. life)</li>
<li>Gives nonstationary policies ( depends on time left)</li>
</ul>
</li>
<li><p>Discounting: use 0 &lt; y &lt; 1</p>
<ul>
<li>Smaller means smaller “horizon” – shorter term focus</li>
</ul>
</li>
<li><p>Absorbing state: guarantee that for every policy, a terminal state will eventually be reached (like “overheated” for racing)</p>
</li>
</ol>
<h3 id="The-Bellman-Equations"><a href="#The-Bellman-Equations" class="headerlink" title="The Bellman Equations"></a>The Bellman Equations</h3><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fsvld0v2gwj312y0lkwfi.jpg" alt=""></p>
<h3 id="Solution1-Value-Iteration"><a href="#Solution1-Value-Iteration" class="headerlink" title="Solution1: Value Iteration"></a>Solution1: Value Iteration</h3><p>Based on Bellman Equations, <strong>fixed depth k</strong> and compute the actual value by <strong>max over all actions</strong> to compute the optimal values:<br><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fsvlmsbeimj30q802idft.jpg" alt=""></p>
<h4 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h4><ol>
<li>It’s slow – O(A*S^2) per iteration</li>
<li>The “max” at each state rarely changes</li>
<li>The policy often converges long before the values</li>
</ol>
<h4 id="Example-3"><a href="#Example-3" class="headerlink" title="Example"></a>Example</h4><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fsvlo457t4j31c80oiwfg.jpg" alt=""></p>
<h3 id="Solution2-Policy-Iteration"><a href="#Solution2-Policy-Iteration" class="headerlink" title="Solution2: Policy Iteration"></a>Solution2: Policy Iteration</h3><p>Because of the problem if value iteration, think of using another way to solve MDP.</p>
<h4 id="Policy-Evaluation"><a href="#Policy-Evaluation" class="headerlink" title="Policy Evaluation"></a>Policy Evaluation</h4><p>Find a way calculate the V’s for a fixed policy.</p>
<h5 id="Fixed-Policies"><a href="#Fixed-Policies" class="headerlink" title="Fixed Policies"></a>Fixed Policies</h5><p>If we fixed some policy (s), then the tree would be simpler: only <strong>one action per state</strong> instead of all actions.</p>
<h5 id="Calculation"><a href="#Calculation" class="headerlink" title="Calculation"></a>Calculation</h5><p>Idea 1: Turn recursive Bellman equations into updates (like value iteration)</p>
<ul>
<li>Efficiency: O(S2) per iteration</li>
</ul>
<p>Idea 2: Without the maxes, the Bellman equations are just a linear system</p>
<ul>
<li>Good for parallel</li>
</ul>
<h4 id="Policy-Extraction"><a href="#Policy-Extraction" class="headerlink" title="Policy Extraction"></a>Policy Extraction</h4><p>“Reversed” Value Iteration: Find a way to calculate the policy given values.</p>
<h5 id="Computing-Actions-from-Values"><a href="#Computing-Actions-from-Values" class="headerlink" title="Computing Actions from Values"></a>Computing Actions from Values</h5><p>Do a mini-expectimax (one step)<br><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fsvljq45ooj30rm034dfu.jpg" alt=""></p>
<h5 id="Computing-Actions-from-Q-Values"><a href="#Computing-Actions-from-Q-Values" class="headerlink" title="Computing Actions from Q-Values"></a>Computing Actions from Q-Values</h5><p>Completely trivial: just choose the max Q-Values action!</p>
<h5 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h5><p>Actions are easier to select from Q-Values than values</p>
<h4 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h4><ol>
<li>Policy evaluation: calculate utilities for some fixed policy (not optimal utilities!) until convergence</li>
<li>Policy improvement: update policy using one-step look-ahead with resulting converged (but not optimal!) utilities as future values</li>
<li>Repeat steps until policy converges</li>
</ol>
<h4 id="Properties-4"><a href="#Properties-4" class="headerlink" title="Properties"></a>Properties</h4><ul>
<li>It’s still optimal!</li>
<li>Can converge (much) faster under some conditions</li>
</ul>
<h3 id="Look-in-depth-These-all-look-the-same"><a href="#Look-in-depth-These-all-look-the-same" class="headerlink" title="Look in depth: These all look the same!"></a>Look in depth: These all look the same!</h3><ul>
<li>They basically are – they are all variations of Bellman updates</li>
<li>They all use one-step lookahead expectimax fragments</li>
<li>They differ only in whether we plug in a fixed policy or max over actions</li>
</ul>
<h3 id="From-MDP-to-learning"><a href="#From-MDP-to-learning" class="headerlink" title="From MDP to learning"></a>From MDP to learning</h3><p>Specifically, reinforcement learning is an MDP, but you couldn’t solve it with just computation (probability unknown). So you needed to actually act to figure it out.</p>
<ul>
<li>Exploration: you have to try unknown actions to get information</li>
<li>Exploitation: eventually, you have to use what you know</li>
<li>Regret: even if you learn intelligently, you make mistakes</li>
<li>Sampling: because of chance, you have to try things repeatedly</li>
<li>Difficulty: learning can be much harder than solving a known MDP</li>
</ul>
<h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><h3 id="Abstraction-3"><a href="#Abstraction-3" class="headerlink" title="Abstraction"></a>Abstraction</h3><ul>
<li>Still assume a Markov decision process (MDP):</li>
<li>A set of states s  S</li>
<li>A set of actions (per state) A</li>
<li>A model T(s,a,s’)</li>
<li>A reward function R(s,a,s’)</li>
<li>Still looking for a policy (s)</li>
<li>New twist: don’t know T or R, must actually try actions and states out to learn</li>
</ul>
<h3 id="Model-Based-Learning"><a href="#Model-Based-Learning" class="headerlink" title="Model-Based Learning"></a>Model-Based Learning</h3><h4 id="Model-Based-Idea"><a href="#Model-Based-Idea" class="headerlink" title="Model-Based Idea"></a>Model-Based Idea</h4><p>Learn an approximate model based on experiences。 Solve for values as if the learned model were correct</p>
<h4 id="Steps-1"><a href="#Steps-1" class="headerlink" title="Steps"></a>Steps</h4><ol>
<li><p>Learn empirical MDP model</p>
<ul>
<li>Count outcomes s’ for each s, a</li>
<li>Normalize to give an estimate of T</li>
<li>Discover each R when we experience (s, a, s’)</li>
</ul>
</li>
<li><p>Solve the learned MDP</p>
<ul>
<li>For example, use value iteration, as before</li>
</ul>
</li>
</ol>
<h4 id="Example-4"><a href="#Example-4" class="headerlink" title="Example"></a>Example</h4><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fszvbs9pfuj31ik0s8gn4.jpg" alt=""></p>
<h3 id="Model-Free-Learning"><a href="#Model-Free-Learning" class="headerlink" title="Model-Free Learning"></a>Model-Free Learning</h3><h4 id="Passive-Reinforcement-Learning"><a href="#Passive-Reinforcement-Learning" class="headerlink" title="Passive Reinforcement Learning"></a>Passive Reinforcement Learning</h4><ul>
<li>Simplified task: policy evaluation</li>
<li>Input: a fixed policy (s)</li>
<li>You don’t know the transitions T(s,a,s’)</li>
<li>You don’t know the rewards R(s,a,s’)</li>
<li>Goal: learn the state values</li>
</ul>
<h4 id="Active-Reinforcement-Learning"><a href="#Active-Reinforcement-Learning" class="headerlink" title="Active Reinforcement Learning"></a>Active Reinforcement Learning</h4><ul>
<li>Full reinforcement learning: optimal policies (like value iteration)</li>
<li>You don’t know the transitions T(s,a,s’)</li>
<li>You don’t know the rewards R(s,a,s’)</li>
<li>You choose the actions now</li>
<li>Goal: learn the optimal policy / values</li>
<li>In this case:<ul>
<li>Learner makes choices!</li>
<li>Fundamental tradeoff: exploration vs. exploitation</li>
<li>This is NOT offline planning!  You actually take actions in the world and find out what happens…</li>
</ul>
</li>
</ul>
<h4 id="Direct-Evaluation"><a href="#Direct-Evaluation" class="headerlink" title="Direct Evaluation"></a>Direct Evaluation</h4><h5 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h5><p>Compute values for each state under</p>
<h5 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h5><p>Average together observed sample values</p>
<ul>
<li>Act according to</li>
<li>Every time you visit a state, write down what the sum of discounted rewards turned out to be</li>
<li>Average those samples</li>
</ul>
<h5 id="Example-5"><a href="#Example-5" class="headerlink" title="Example"></a>Example</h5><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1ft0098h4lej31jw0soq3y.jpg" alt=""></p>
<h5 id="Problems-1"><a href="#Problems-1" class="headerlink" title="Problems"></a>Problems</h5><p>Advantage</p>
<ul>
<li>It’s easy to understand</li>
<li>It doesn’t require any knowledge of T, R</li>
<li>It eventually computes the correct average values, using just sample transitions</li>
</ul>
<p>Disadvantage</p>
<ul>
<li>It wastes information about state connections</li>
<li>Each state must be learned separately</li>
<li>So, it takes a long time to learn</li>
</ul>
<h4 id="Temporal-Difference-Learning"><a href="#Temporal-Difference-Learning" class="headerlink" title="Temporal Difference Learning"></a>Temporal Difference Learning</h4><h5 id="Idea-1"><a href="#Idea-1" class="headerlink" title="Idea"></a>Idea</h5><p>Sample-Based Policy Evaluation. Learn from every experience.</p>
<ul>
<li>Update V(s) each time we experience a transition (s, a, s’, r)</li>
<li>Likely outcomes s’ will contribute updates more often</li>
</ul>
<h5 id="Example-6"><a href="#Example-6" class="headerlink" title="Example"></a>Example</h5><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1ft00ce42xej31j20swjs9.jpg" alt=""></p>
<h5 id="Problems-2"><a href="#Problems-2" class="headerlink" title="Problems"></a>Problems</h5><p>TD value leaning is a model-free way to do policy evaluation, mimicking Bellman updates with running sample averages. However, if we want to turn values into a (new) policy, we’re sunk. Solution: learn Q-values, not values.</p>
<h4 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q-Learning"></a>Q-Learning</h4><h5 id="Idea-amp-Steps"><a href="#Idea-amp-Steps" class="headerlink" title="Idea &amp; Steps"></a>Idea &amp; Steps</h5><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1ft00hjx84oj31ja0nidhz.jpg" alt=""></p>
<h5 id="Properties-5"><a href="#Properties-5" class="headerlink" title="Properties"></a>Properties</h5><ul>
<li>Converges to optimal policy – even if you’re acting suboptimally</li>
</ul>
<h5 id="Caveats"><a href="#Caveats" class="headerlink" title="Caveats"></a>Caveats</h5><ul>
<li>Have to explore enough.</li>
<li>Have to eventually make the learning rate small enough but not decrease it too quickly.</li>
<li>Basically, in the limit, it doesn’t matter how you select actions.</li>
</ul>

      
    </div>

    

    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Donate</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="Jiaxi He WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Notes/" rel="tag"># Notes</a>
          
            <a href="/tags/Artificial-Intelligence/" rel="tag"># Artificial Intelligence</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Irrational/" rel="next" title="Notes of Predictably Irrational">
                <i class="fa fa-chevron-left"></i> Notes of Predictably Irrational
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/zulu/" rel="prev" title="读书笔记：祖鲁法则:如何选择成长股">
                读书笔记：祖鲁法则:如何选择成长股 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- Go to www.addthis.com/dashboard to customize your tools -->
<div class="addthis_inline_share_toolbox">
  <script type = "text/javascript" src = "//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b1cfece61fa2af8" async = "async" ></script>
</div>

      
    </div>
  </div>


          </div>
          

  
    <div class="comments" id="comments">
      
        <div id="gitment-container"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Jiaxi He" />
            
              <p class="site-author-name" itemprop="name">Jiaxi He</p>
              <p class="site-description motion-element" itemprop="description">Jiaxi He's personal page</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/henryhoo" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.facebook.com/jiaxi.henry.he" target="_blank" title="FB Page"><i class="fa fa-fw fa-facebook"></i>FB Page</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://stackoverflow.com/users/6211857/jiaxi-he" target="_blank" title="StackOverflow"><i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.instagram.com/jiaxi_h" target="_blank" title="Instagram"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.linkedin.com/in/jiaxih/" target="_blank" title="Linkedin"><i class="fa fa-fw fa-linkedin"></i>Linkedin</a>
                  
                </span>
              
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://xingyaohuang.com" title="Xingyao" target="_blank">Xingyao</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://yiwencui.wixsite.com/portfolio" title="Yiwen" target="_blank">Yiwen</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Search"><span class="nav-number">1.</span> <span class="nav-text">Search</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Two-type-of-search"><span class="nav-number">1.1.</span> <span class="nav-text">Two type of search</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Planning-sequences-of-actions"><span class="nav-number">1.1.1.</span> <span class="nav-text">Planning: sequences of actions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Identification-assignments-to-variables"><span class="nav-number">1.1.2.</span> <span class="nav-text">Identification: assignments to variables</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Uninformed-and-Informed-Search-Planning"><span class="nav-number">1.2.</span> <span class="nav-text">Uninformed and Informed Search (Planning)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Abstraction"><span class="nav-number">1.2.1.</span> <span class="nav-text">Abstraction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Example"><span class="nav-number">1.2.2.</span> <span class="nav-text">Example</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Properties"><span class="nav-number">1.2.3.</span> <span class="nav-text">Properties</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Depth-First-Search-DFS"><span class="nav-number">1.2.4.</span> <span class="nav-text">Depth-First Search (DFS)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Breadth-First-Search-BFS"><span class="nav-number">1.2.5.</span> <span class="nav-text">Breadth-First Search (BFS)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Uniform-Cost-Search-UCS"><span class="nav-number">1.2.6.</span> <span class="nav-text">Uniform Cost Search (UCS)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Greedy-Search"><span class="nav-number">1.2.7.</span> <span class="nav-text">Greedy Search</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#A-Combining-UCS-and-Greedy"><span class="nav-number">1.2.8.</span> <span class="nav-text">A*: Combining UCS and Greedy</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Admissibility"><span class="nav-number">1.2.8.1.</span> <span class="nav-text">Admissibility</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Consistency"><span class="nav-number">1.2.8.2.</span> <span class="nav-text">Consistency</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Heuristic-design"><span class="nav-number">1.2.8.3.</span> <span class="nav-text">Heuristic design</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Comparison"><span class="nav-number">1.2.8.4.</span> <span class="nav-text">Comparison</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Constraint-Satisfaction-Problems-Identification"><span class="nav-number">1.3.</span> <span class="nav-text">Constraint Satisfaction Problems (Identification)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Abstraction-1"><span class="nav-number">1.3.1.</span> <span class="nav-text">Abstraction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Example-1"><span class="nav-number">1.3.2.</span> <span class="nav-text">Example</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Backtracking-Search"><span class="nav-number">1.3.3.</span> <span class="nav-text">Backtracking Search</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Improving-Backtracking"><span class="nav-number">1.3.4.</span> <span class="nav-text">Improving Backtracking</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Filtering"><span class="nav-number">1.3.4.1.</span> <span class="nav-text">Filtering</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Forward-Checking"><span class="nav-number">1.3.4.1.1.</span> <span class="nav-text">Forward Checking</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Constraint-Propagation"><span class="nav-number">1.3.4.1.2.</span> <span class="nav-text">Constraint Propagation</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#K-Consistency"><span class="nav-number">1.3.4.1.3.</span> <span class="nav-text">K-Consistency</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Strong-K-Consistency"><span class="nav-number">1.3.4.1.4.</span> <span class="nav-text">Strong K-Consistency</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Ordering"><span class="nav-number">1.3.4.2.</span> <span class="nav-text">Ordering</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Minimum-remaining-values-MRV"><span class="nav-number">1.3.4.2.1.</span> <span class="nav-text">Minimum remaining values (MRV)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Least-Constraining-Value-LCV"><span class="nav-number">1.3.4.2.2.</span> <span class="nav-text">Least Constraining Value (LCV)</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Structure"><span class="nav-number">1.3.4.3.</span> <span class="nav-text">Structure</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Subproblems"><span class="nav-number">1.3.4.3.1.</span> <span class="nav-text">Subproblems</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Tree-Structured-CSPs"><span class="nav-number">1.3.4.3.2.</span> <span class="nav-text">Tree-Structured CSPs</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Cutset"><span class="nav-number">1.3.4.3.3.</span> <span class="nav-text">Cutset</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Local-search-Iterative-Algorithms-for-CSPs"><span class="nav-number">1.3.5.</span> <span class="nav-text">Local search: Iterative Algorithms for CSPs</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Performance"><span class="nav-number">1.3.5.1.</span> <span class="nav-text">Performance</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adversarial-Search-Minimax-Tree"><span class="nav-number">1.4.</span> <span class="nav-text">Adversarial Search (Minimax Tree)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Resource-Limits"><span class="nav-number">1.4.1.</span> <span class="nav-text">Resource Limits</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Solution1-Depth-limited-search"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">Solution1: Depth limited search</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Properties-1"><span class="nav-number">1.4.1.1.1.</span> <span class="nav-text">Properties</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Evaluation-Functions"><span class="nav-number">1.4.1.1.2.</span> <span class="nav-text">Evaluation Functions</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Solution2-Alpha-Beta-Pruning"><span class="nav-number">1.4.1.2.</span> <span class="nav-text">Solution2: Alpha-Beta Pruning</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#General-steps"><span class="nav-number">1.4.1.2.1.</span> <span class="nav-text">General steps</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Properties-2"><span class="nav-number">1.4.1.2.2.</span> <span class="nav-text">Properties</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Uncertainty-and-Utilities"><span class="nav-number">1.5.</span> <span class="nav-text">Uncertainty and Utilities</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Expectimax-Search"><span class="nav-number">1.5.1.</span> <span class="nav-text">Expectimax Search</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Expectiminmax-Search-Mixed-Layer"><span class="nav-number">1.5.2.</span> <span class="nav-text">Expectiminmax Search (Mixed Layer)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Properties-3"><span class="nav-number">1.5.2.1.</span> <span class="nav-text">Properties</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Example-2"><span class="nav-number">1.5.2.2.</span> <span class="nav-text">Example</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Generalization-of-minimax"><span class="nav-number">1.5.3.</span> <span class="nav-text">Generalization of minimax</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Maximum-Expected-Utility-Principle"><span class="nav-number">1.5.4.</span> <span class="nav-text">Maximum Expected Utility Principle</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Markov-Decision-Processes-MDP"><span class="nav-number">2.</span> <span class="nav-text">Markov Decision Processes (MDP)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Abstraction-2"><span class="nav-number">2.1.</span> <span class="nav-text">Abstraction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Quantities"><span class="nav-number">2.2.</span> <span class="nav-text">Quantities</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Examples"><span class="nav-number">2.3.</span> <span class="nav-text">Examples</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Utilities-of-Sequences"><span class="nav-number">2.4.</span> <span class="nav-text">Utilities of Sequences</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Discounting"><span class="nav-number">2.4.1.</span> <span class="nav-text">Discounting</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Example-discount-of-0-5"><span class="nav-number">2.4.1.1.</span> <span class="nav-text">Example: discount of 0.5</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Infinite-Utilities"><span class="nav-number">2.4.2.</span> <span class="nav-text">Infinite Utilities</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Solution"><span class="nav-number">2.4.2.1.</span> <span class="nav-text">Solution</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Bellman-Equations"><span class="nav-number">2.5.</span> <span class="nav-text">The Bellman Equations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Solution1-Value-Iteration"><span class="nav-number">2.6.</span> <span class="nav-text">Solution1: Value Iteration</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Problems"><span class="nav-number">2.6.1.</span> <span class="nav-text">Problems</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Example-3"><span class="nav-number">2.6.2.</span> <span class="nav-text">Example</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Solution2-Policy-Iteration"><span class="nav-number">2.7.</span> <span class="nav-text">Solution2: Policy Iteration</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Policy-Evaluation"><span class="nav-number">2.7.1.</span> <span class="nav-text">Policy Evaluation</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Fixed-Policies"><span class="nav-number">2.7.1.1.</span> <span class="nav-text">Fixed Policies</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Calculation"><span class="nav-number">2.7.1.2.</span> <span class="nav-text">Calculation</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Policy-Extraction"><span class="nav-number">2.7.2.</span> <span class="nav-text">Policy Extraction</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Computing-Actions-from-Values"><span class="nav-number">2.7.2.1.</span> <span class="nav-text">Computing Actions from Values</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Computing-Actions-from-Q-Values"><span class="nav-number">2.7.2.2.</span> <span class="nav-text">Computing Actions from Q-Values</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Conclusion"><span class="nav-number">2.7.2.3.</span> <span class="nav-text">Conclusion</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Steps"><span class="nav-number">2.7.3.</span> <span class="nav-text">Steps</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Properties-4"><span class="nav-number">2.7.4.</span> <span class="nav-text">Properties</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Look-in-depth-These-all-look-the-same"><span class="nav-number">2.8.</span> <span class="nav-text">Look in depth: These all look the same!</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#From-MDP-to-learning"><span class="nav-number">2.9.</span> <span class="nav-text">From MDP to learning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reinforcement-Learning"><span class="nav-number">3.</span> <span class="nav-text">Reinforcement Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Abstraction-3"><span class="nav-number">3.1.</span> <span class="nav-text">Abstraction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-Based-Learning"><span class="nav-number">3.2.</span> <span class="nav-text">Model-Based Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Model-Based-Idea"><span class="nav-number">3.2.1.</span> <span class="nav-text">Model-Based Idea</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Steps-1"><span class="nav-number">3.2.2.</span> <span class="nav-text">Steps</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Example-4"><span class="nav-number">3.2.3.</span> <span class="nav-text">Example</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-Free-Learning"><span class="nav-number">3.3.</span> <span class="nav-text">Model-Free Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Passive-Reinforcement-Learning"><span class="nav-number">3.3.1.</span> <span class="nav-text">Passive Reinforcement Learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Active-Reinforcement-Learning"><span class="nav-number">3.3.2.</span> <span class="nav-text">Active Reinforcement Learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Direct-Evaluation"><span class="nav-number">3.3.3.</span> <span class="nav-text">Direct Evaluation</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Goal"><span class="nav-number">3.3.3.1.</span> <span class="nav-text">Goal</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Idea"><span class="nav-number">3.3.3.2.</span> <span class="nav-text">Idea</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Example-5"><span class="nav-number">3.3.3.3.</span> <span class="nav-text">Example</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Problems-1"><span class="nav-number">3.3.3.4.</span> <span class="nav-text">Problems</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Temporal-Difference-Learning"><span class="nav-number">3.3.4.</span> <span class="nav-text">Temporal Difference Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Idea-1"><span class="nav-number">3.3.4.1.</span> <span class="nav-text">Idea</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Example-6"><span class="nav-number">3.3.4.2.</span> <span class="nav-text">Example</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Problems-2"><span class="nav-number">3.3.4.3.</span> <span class="nav-text">Problems</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Q-Learning"><span class="nav-number">3.3.5.</span> <span class="nav-text">Q-Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Idea-amp-Steps"><span class="nav-number">3.3.5.1.</span> <span class="nav-text">Idea &amp; Steps</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Properties-5"><span class="nav-number">3.3.5.2.</span> <span class="nav-text">Properties</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Caveats"><span class="nav-number">3.3.5.3.</span> <span class="nav-text">Caveats</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2016 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiaxi He</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Pisces</a> v6.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.2.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.2.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.2.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.2.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.2.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.2.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.2.0"></script>



  



	





  





  






<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    
      <script type="text/javascript">
      function renderGitment(){
        var gitment = new Gitmint({
            id: window.location.pathname,
            owner: 'henryhoo',
            repo: 'gitment-comments',
            
            lang: "" || navigator.language || navigator.systemLanguage || navigator.userLanguage,
            
            oauth: {
            
            
                client_secret: 'eefef5b8d79ba2ec15878ee3e547a2271476bf21',
            
                client_id: '1bf3b07032854409cd99'
            }});
        gitment.render('gitment-container');
      }

      
      renderGitment();
      
      </script>
    






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      
        // ref: https://github.com/ForbesLindesay/unescape-html
        var unescapeHtml = function(html) {
          return String(html)
            .replace(/&quot;/g, '"')
            .replace(/&#39;/g, '\'')
            .replace(/&#x3A;/g, ':')
            // replace all the other &#x; chars
            .replace(/&#(\d+);/g, function (m, p) { return String.fromCharCode(p); })
            .replace(/&lt;/g, '<')
            .replace(/&gt;/g, '>')
            .replace(/&amp;/g, '&');
        };
      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                content = unescapeHtml(content);
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("zRg8LmYzOw19YgrvP6rkepru-gzGzoHsz", "FsTvxeDNJU2y2eVJMIHoEn1r");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            
            counter.save(null, {
              success: function(counter) {
                
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(counter.get('time'));
                
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            
              var newcounter = new Counter();
              /* Set ACL */
              var acl = new AV.ACL();
              acl.setPublicReadAccess(true);
              acl.setPublicWriteAccess(true);
              newcounter.setACL(acl);
              /* End Set ACL */
              newcounter.set("title", title);
              newcounter.set("url", url);
              newcounter.set("time", 1);
              newcounter.save(null, {
                success: function(newcounter) {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
                },
                error: function(newcounter, error) {
                  console.log('Failed to create');
                }
              });
            
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  

  
  

  

  

  

  

  

</body>
</html>
